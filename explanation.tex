\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[utf8]{vietnam}
\usepackage[left=3cm,right=3cm,top=3cm,bottom=3cm]{geometry}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{cases}

\title{Biện luận bài tập tuần 2. INT3305 1}
\author{Ngô Quang Dương -- 17020191}
\date{\today}

\begin{document}

\maketitle

\par\textbf{Bài tập 1a.}

\begin{itemize}
    \item Xác suất để phép thử Bernoulli thành công là $p$. Do đó, xác suất để sau $n$ lần thực hiện phép thử mới có một lần thành công là:
        \[ \Pr(n) = p(1-p){}^{n-1} \]
    \item Tổng của $N$ xác suất đầu tiên là:
        \begin{align*}
            \sum^{N}_{n=1}p(1-p){}^{n-1} &= p\sum^{N}_{n=1}(1-p){}^{n-1} \\
                                       &= p\cdot\frac{1 - (1 - p){}^{N}}{1 - (1-p)} \\
                                       &= 1 - (1 - p){}^{N}
        \end{align*}
        \par Đẳng thức trên cho thấy khi $N\to+\infty$ thì $\displaystyle\sum\limits^{N}_{n=1}p(1-p){}^{n-1}\to 1$.
        \par Do đó hàm \texttt{sumProb (N, p)} có thể được sử dụng để kiểm chứng tổng xác suất của phân bố geometric bằng $1$.
    \item Đặt $H(N) = \text{\texttt{approxEntropy}}(N,p)$
        \par Các $H(N)$ tạo thành một dãy số.
        \begin{align*}
            \text{Entropy} &= \sum^{\infty}_{n=1}p(1-p){}^{n-1}\log\frac{1}{p(1-p){}^{n-1}} \\
                 &= p\sum^{\infty}_{n=1}(1-p){}^{n-1}\left(\log\frac{1}{p} + (n-1)\log\frac{1}{1-p}\right) \\
                 &= p\log\frac{1}{p}\sum^{\infty}_{n=1}(1-p){}^{n-1} + p\log\frac{1}{1-p}\sum^{\infty}_{n=1}(n-1)(1-p){}^{n-1} \\
                 &= p\log\frac{1}{p}\cdot\frac{1}{p} + p\log\frac{1}{1-p}\cdot\frac{1-p}{(1-(1-p)){}^{2}} \\
                 &= \log\frac{1}{p} + \frac{1-p}{p}\log\frac{1}{1-p}
        \end{align*}
        \par Dãy $H(N)$ là dãy tăng, có giới hạn như trên, do đó $H(N)$ có thể xấp xỉ entropy của nguồn tin geometric, tức là hàm \texttt{approxEntropy (N, p)} xấp xỉ entropy.
\end{itemize}

\newpage

\par\textbf{Bài tập 1b.}

\begin{itemize}
    \item Xác suất để sau $N$ lần thực hiện phép thử Bernoulli, có đúng $n$ lần thành công là:
        \[ \Pr(n) = \binom{N}{n}p^{n}(1-p){}^{N-n} \]
    \item Tổng của $N$ xác suất của nguồn tin nhị thức là:
        \[
            \sum^{N}_{n=0}\binom{N}{n}p^{n}(1-p){}^{N-n} = (p + 1- p){}^{N} = 1
        \]
        \par Do đó hàm \texttt{sumProb (N, p)} có thể dùng để kiểm tra tổng xác suất của phân bố nhị thức bằng $1$ (máy tính chỉ tính được xấp xỉ).
    \item Khác với phân bố geometric, phân bố nhị thức chỉ mang lại hữu hạn symbol, do đó hàm \texttt{approxEntropy (N, p)} xấp xỉ entropy.
\end{itemize}

\newpage

\par\textbf{Bài tập 1c.}

\begin{itemize}
    \item Để có được $r$ lần thử thành công, ta cần thực hiện $n$ lần, trong đó:
        \[ n\in\{ r, r + 1, r + 2, \ldots \} \]
        \par Nhưng trong $n$ lần thử, lần cuối cùng là lần thành công, nên số cách chọn ra những lần thành công trong $n - 1$ lần thử trước đó là $\dbinom{n - 1}{r - 1}$.
        \par Do đó, xác suất để sau $n$ lần thực hiện phép thử Bernoulli mới có được $r$ lần thành công là:
        \[ \Pr(n) = \binom{n - 1}{r - 1}p^{r}(1 - p){}^{n - r} = \binom{n - 1}{n - r}p^{r}(1 - p){}^{n - r} \]
    \item Sử dụng khai triển Taylor
        \[ (1 + x){}^{\alpha} = \sum^{\infty}_{n=0}\binom{\alpha}{n}x^{n}  \]
        \par trong đó $\alpha$ là một số thực và:
        \[ \binom{\alpha}{n} = \frac{\alpha(\alpha - 1)\cdots (\alpha - n + 1)}{n!} \]
        \par Dựa vào hai công thức trên, ta kiểm tra tổng xác suất:
        \begin{align*}
            \sum^{\infty}_{n=r}\binom{n-1}{r-1}p^{r}(1-p){}^{n-r} &= \sum^{\infty}_{k=0}\binom{k + r - 1}{k}p^{r}(1-p){}^{k}\quad(\text{đặt }k = n - r) \\
                                                                &= p^{r}\sum^{\infty}_{k=0}\frac{(k + r - 1)!}{(r - 1)!k!}(1 - p){}^{k} \\
                                                                &= p^{r}\sum^{\infty}_{k=0}\frac{r(r+1)\cdots (r + k - 1)}{k!}(1-p){}^{k} \\
                                                                &= p^{r}\sum^{\infty}_{k=0}(-1){}^{k}\frac{(-r)(-r - 1)\cdots (-r -k + 1)}{k!}(1-p){}^{k} \\
                                                                &= p^{r}\sum^{\infty}_{k=0}\binom{-r}{k}(p-1){}^{k} \\
                                                                &= p^{r}(1 + p - 1){}^{-r} = 1
        \end{align*}
        \par Quay trở lại với hàm \texttt{sumProb(N, p, r)}.
        \par Ta xét dãy $a_{N} = \text{\texttt{sumProb(N, p, r)}}$. Đây là một dãy dương, tăng và có giới hạn bằng $1$ (theo chứng minh trên). Do đó khi $N\to{+\infty}$ thì $a_{N}\to 1$. Vì vậy hàm \texttt{sumProb(N, p, r)} có thể được sử dụng để kiểm tra tổng xác suất của phân bố nhị thức âm bằng $1$.
\end{itemize}

\end{document}
